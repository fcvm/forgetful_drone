\chapter{Experiments in Simulation}
\label{maintwo}

\section{Simulation Setup} \label{sec:sim_setup}
The experiments in this thesis 
are conducted in a drone racing simulation,
which includes the environment, 
the racetrack consisting of race gates 
and the drone.
The implementation of the simulation (see fig. \ref{fig:simulation_setup})
is separated into physics modeling and image rendering.
\begin{figure}%[h]
    \centering
    \includegraphics[width=1.0\textwidth]{own/simulation_setup.drawio.pdf}
    \caption[
        Implementation concept of the simulation
    ]{
        Implementation concept of the simulation
    \label{fig:simulation_setup}
    }
\end{figure}

For a physics modeling of high accuracy,
the Gazebo\footnote{\url{https://gazebosim.org/home}, accessed on \today} 
simulator
with the RotorS \cite{Furrer2016} plugin is deployed.
The modeling includes the dynamics of the drone under 
the actuation with inputted motor speed commands
and possible collisions of the drone with the racetrack gates.
Further, the RotorS plugin provides the
drone state estimate, the motor speeds estimate and the
data from the onboard IMU as output.


For an almost photo-realistic image rendering,
the Flightmare \cite{Song2020} simulator 
is deployed.
Upon request, the Flightlib interface
updates the drone pose 
within the Unity\footnote{
    \url{https://unity.com/}, accessed on \today
} Engine
and fetches an RGB image from the drone's onboard camera.
Before running the simulation,
the Unity Engine is built from a Unity project
based on the RPG Flightmare Unity Project\footnote{
    \url{https://github.com/uzh-rpg/flightmare_unity}, accessed on \today
}.
The Unity project of this thesis
entails five scenes
named
spaceship interior\footnote{
    based on "3D Free Modular Kit" from the Unity Asset Store
},
destroyed city\footnote{
    based on "Destroyed City FREE" from the Unity Asset Store
},
industrial site\footnote{
    based on "RPG/FPS Game Assets for PC/Mobile (Industrial Set v2.0)" from the Unity Asset Store
},
polygon city\footnote{
    based on "CITY package" from the Unity Asset Store
}
and desert mountain\footnote{
    based on "Free Island Collection" from the Unity Asset Store
}
(see fig. \ref{fig:unity_scenes}).
The scenes base on assets from the Unity Asset Store\footnote{
    \url{https://assetstore.unity.com/}, accessed on \today
}.
Within each scene, there are three sites (A, B, C) to place a racetrack.
For the racetrack, two different gate types are provided:
the first with TU Berlin/DAI-Labor logos and 
the second with Tsinghua University/DME logos
(see fig. \ref{fig:unity_gates}).
\begin{figure}
    \centering
    \subfloat[
        Spaceship Interior
    ]{
        \label{fig:unity_scene_SI}
        \includegraphics[width=0.33\textwidth]{own/jpg/spaceship_interior.jpg}
    }
    %\hspace*{0cm}                
    \subfloat[
        Destroyed City
    ]{
        \label{fig:unity_scene_DC}
        \includegraphics[width=0.33\textwidth]{own/jpg/destroyed_city.jpg}
    }
    \par
    \subfloat[
        Industrial Site
    ]{
        \label{fig:unity_scene_IS}
        \includegraphics[width=0.33\textwidth]{own/jpg/industrial_site.jpg}
    }
    \subfloat[
        Polygon City
    ]{
        \label{fig:unity_scene_PC}
        \includegraphics[width=0.33\textwidth]{own/jpg/polygon_city.jpg}
    }
    \subfloat[
        Desert Mountain
    ]{
        \label{fig:unity_scene_DM}
        \includegraphics[width=0.33\textwidth]{own/jpg/desert_mountain.jpg}
    }
    \caption[
        Scenes available in simulation
    ]{
        Scenes available in simulation
        \label{fig:unity_scenes}
    }
\end{figure}
\begin{figure}[h]
    \centering
    \subfloat[
        DAI-Labor at TU Berlin
    ]{
        %\label{fig:unity_scene_SI}
        \includegraphics[width=0.33\textwidth]{own/jpg/tub_dai_gate.png}
    }       
    \subfloat[
        DME at Tsinghua University
    ]{
        %\label{fig:unity_scene_DC}
        \includegraphics[width=0.33\textwidth]{own/jpg/thu_dme_gate.png}
    }
    \caption[
        Race gates available in simulation
    ]{
        Race gates available in simulation
        \label{fig:unity_gates}
    }
\end{figure}

The Forgetful Simulator node takes on two tasks.
First, it synchronizes the
drone state in the Flightmare simulator with the
ground-truth state in the Gazebo simulator and 
provides the RGB images fetched from the Flightmare simulator
as output.
Second, the node sets up the simulation
according to the inputted 
simulation configuration.

A simulation configuration 
includes the environment and the racetrack configuration.
The environment configuration specifies
the scene and the site.
The racetrack configuration
specifies the 
racetrack type, the racetrack generation,
the racetrack direction and the racetrack gates.
Table \ref{tab:sim_config_opts} shows all available options for the simulation configuration.
\begin{table}[h]
    \caption{Simulation configuration options
    \label{tab:sim_config_opts}}
    \centering
    \begin{tabular}{|c|c|c|p{6cm}|} \hline
        \multirow{8}{*}{Simulation} 
        &\multirow{4}{*}{Environment}   
        &\multirow{3}{*}{Scenes}
        &Spaceship interior, destroyed city, industrial site, polygon city, desert mountain    
        \\\cline{3-4}
        &
        &Sites
        &A, B, C
        \\\cline{2-4}
        &\multirow{4}{*}{Racetrack}
        &Types
        &Figure-8, gap                                                                         \\\cline{3-4}
        &
        &Generations
        &Deterministic, randomized
        \\\cline{3-4}
        &
        &Directions
        &Counterclockwise, clockwise
        \\\cline{3-4}
        &
        &Gates
        &TUB-DAI, THU-DME
        \\\hline
    \end{tabular}
\end{table}
The Forgetful Simulator node stores 
the gate poses for both 
deterministic and counterclockwise
racetrack types
(see table \ref{tab:gate_pos}).
If specified,
these poses are randomized
and redirected from counterclockwise to clockwise
as illustrated in figure \ref{fig:racetrack_comp}.
The racetrack randomization 
%starts from the stored gate poses of the specified racetrack type and 
includes the following steps.
\begin{enumerate}
    \item Sample the y-position values 
    of the gates \#3-6 from the uniform real distribution
    over the intervals specified in table \ref{tab:gate_pos}.
    This step only applies to the gap racetrack type,
    as it explicitly randomizes the gap distance.
    \item Shift the gate positions along the $x$-, $y$- and $z$-axis
    by a value, which is sampled
    independently for each gate and axis
    from the uniform real distribution
    over the user-specified interval 
    $\left[
        \text{-}\dist[\user]{\text{sim}}{\text{shift},\mxm}{}{},
        \dist[\user]{\text{sim}}{\text{shift},\mxm}{}{}\right]$.
    \item Scale the gate positions by a value,
    which is sampled once for all gates from the uniform real distribution
    over the user-specified interval
    $\left[
        \dist[\user]{\text{sim}}{\text{shift},\mnm}{}{}, 
        \dist[\user]{\text{sim}}{\text{shift},\mxm}{}{}\right]$.
    \item Twist the gate yaw-orientations
    by a value, which is sampled 
    independently for each gate 
    from the uniform real distribution
    over the user-specified interval
    $\left[
        -\dist[\user]{\text{sim}}{\text{twist},\mxm}{}{},
        \dist[\user]{\text{sim}}{\text{twist},\mxm}{}{}\right]$.
\end{enumerate}
After processing the racetrack configuration,
the Forgetful Simulator node computes
the start position of the drone so that
the drone is located between the second last and the last gate
and faces towards the last gate.
Then, the node loads the 
environment configuration
in the Flightmare Simulator 
and 
spawns the drone model 
and the race gate models of the specified type
at the computed poses
in both the Flightmare and the Gazebo simulator.
Finally, the node
outputs the computed gate poses.
This information is required 
to compute the global trajectory of the expert system
(see section \ref{sec:expert_system})
and to update the drone's progress on the racetrack automatically
whenever the drone has passed the currently targeted race gate.













\begin{table}[h]
    \footnotesize
    \caption{Deterministic gate poses\label{tab:gate_pos}}
    \centering
    \begin{tabular}{|l|l|l|l|l|l|}
    %\hline
    %\multicolumn{3}{|c|}{Team sheet} \\
    \hline
    Racetrack & Gate & x & y & z & yaw\\ 
    \hline
    \multirow{14}{*}{Figure-8}   
    &0 &-20.45& -8.65&2.0& 1.13\\ \cline{2-6}
    &1 &-12.55&-11.15&2.0&-1.57\\ \cline{2-6}
    &2 &-4.15 & -5.35&2.0&-0.60\\ \cline{2-6}
    &3 &3.45  &  4.25&2.0&-0.63\\ \cline{2-6}
    &4 &11.95 & 11.15&2.0&-1.21\\ \cline{2-6}
    &5 &21.85 &  6.85&2.0& 0.99\\ \cline{2-6}
    &6 &24.25 & -1.75&2.0& 0.00\\ \cline{2-6}
    &7 &19.25 & -9.55&2.0&-1.03\\ \cline{2-6}
    &8 &10.55 &-10.65&2.0& 1.53\\ \cline{2-6}
    &9 &2.85  & -5.95&2.0& 0.57\\ \cline{2-6}
    &10&-4.95 &  4.65&2.0& 0.67\\ \cline{2-6}
    &11&-12.95&  9.65&2.0&-1.53\\ \cline{2-6}
    &12&-21.05&  6.65&2.0&-0.77\\ \cline{2-6}
    &13&-24.25& -1.00&2.0& 0.07\\
    \hline
    \multirow{14}{*}{Gap}   
    &0 &-20.45&-8.65         &2.0& 1.13\\ \cline{2-6}
    &1 &-12.55&-11.15        &2.0&-1.57\\ \cline{2-6}
    &2 &-4.15 &-9.35         &2.0& -1.0\\ \cline{2-6}
    &3 &4.85  &[-4.95, -5.95]&2.0& -1.4\\ \cline{2-6}
    &4 &16.95 &[-2.25, -5.25]&2.0& 1.57\\ \cline{2-6}
    &5 &16.95 &[2.25,   5.25]&2.0& 1.57\\ \cline{2-6}
    &6 &5.45  &[4.45,   5.45]&2.0&  1.4\\ \cline{2-6}
    &7 &-4.95 &7.95          &2.0&  1.2\\ \cline{2-6}
    &8 &-12.95&9.65          &2.0&-1.53\\ \cline{2-6}
    &9 &-21.05&6.65          &2.0&-0.77\\ \cline{2-6}
    &10&-24.25&-1.0          &2.0& 0.07\\
    \hline
    \end{tabular}
\end{table}






%\section{ANN Module Variants}
%In the experiments, several
%variants of the ANN module (see section \ref{sec:ann_module})
%are examined for their race performance.
%Table \ref{tab:ann_module_variants} shows these variants
%and their configurations.
%The configuration of a variant
%is structured into
%input, output and the 
%CNN, GRU, FC, and HEAD submodule.
%
%The input configuration includes:
%the sequence length $\seqLen$ of the training samples 
%(see equ. \ref{eq:seq_len}),
%the resize factor $\resizeFact$ 
%of the image preprocessing (see equ. \ref{eq:rgb_preproc})
%as well as the switchable optional inputs
%$\rawRGBTimeStep$, 
%$(\IMULinAcc,\IMUAngVel)$
%and
%$\IMUTimeStep$ (see equ. \ref{eq:opt_inp_vec}).
%The output configuration includes:
%navigation decision
%$\headNavDec$ (see equ. \ref{eq:head_nav_dec})
%and control command
%$\headCtrlCmd$ (see equ. \ref{eq:head_ctrl_cmd}).
%For the
%configurations regarding the CNN, GRU, FC and HEAD submodules,
%see the corresponding paragraphs in section \ref{sec:ann_module}. 
%
%
%%All of the examined variants have three configurational aspects in common.
%%First, all available optional inputs are activated.
%%Second, navigation decisions are selected as output option.
%%Third, the CNN submodule implements the backbone of the ResNet18 PyTorch implementation
%%whose parameters are trainable and pretrained on ImageNet !!!.
%%The ResNet18 contains 18 layers and has ... trainable parameters ...
%
%\providecommand{\ncols}{}
%\renewcommand{\ncols}{5}
%\begin{table}[h]
%    \caption{ANN module variants\label{tab:ann_module_variants}}
%    \centering
%    \begin{tabular}{|l|l|l|l|l|} \hline
%                        &                           &Baseline               &Baseline+              & Sequential \\\hline\hline
%\multirow{2}{*}{Train.} &Scene                      &$\setOfInts{1,2,3,4}$  &$\setOfInts{1,2,3,4}$  &$\setOfInts{1,2,3,4}$  \\\cline{2-\ncols}
%                        &Racetrack type             &Gap                    &Gap                    &Gap                    \\\hline
%\multirow{5}{*}{Input}  &$\seqLen$                  &1                      &1                      &$\setOfInts{2,3,5,10,25}$             \\\cline{2-\ncols}
%                        &$\resizeFact$              &\sfrac{1}{2}           &\sfrac{1}{2}           &$\setOfInts{\sfrac{1}{2}, \sfrac{1}{3}}$   \\\cline{2-\ncols}
%                        &$\rawRGBTimeStep$          &\xmark                 &\cmark                 &\cmark         \\\cline{2-\ncols}
%                        &$(\IMULinAcc,\IMUAngVel)$  &\xmark                 &\cmark                 &\cmark         \\\cline{2-\ncols}
%                        &$\IMUTimeStep$             &\xmark                 &\cmark                 &\cmark         \\\hline
%\multirow{1}{*}{Output} &$\headNavDec$              &\cmark                 &\cmark                 &\cmark         \\\cline{2-\ncols}
%                        &$\headCtrlCmd$             &\xmark                 &\xmark                 &\xmark         \\\hline
%\multirow{3}{*}{CNN}    &Model                      &resnet8                &resnet18               &resnet18       \\\cline{2-\ncols}
%                        &Pretrained                 &\xmark                 &\cmark                 &\cmark         \\\cline{2-\ncols}
%                        &Trainable                  &\cmark                 &\xmark                 &\cmark         \\\hline
%\multirow{3}{*}{GRU}    &$\GRUNumLayer$             &\xmark                 &\xmark                 &3              \\\cline{2-\ncols}
%                        &$\GRUHiddenSize$           &\xmark                 &\xmark                 &16             \\\cline{2-\ncols}
%                        &$\GRUDropoutP$             &\xmark                 &\xmark                 &0.5            \\\hline
%\multirow{4}{*}{FC}     &$\fcLayer$                 &1                      &3                      &\xmark         \\\cline{2-\ncols}
%                        &$\fcOut$                   &256                    &32                     &\xmark         \\\cline{2-\ncols}
%                        &$\fcDropoutProb$           &0.5                    &0.2063                 &\xmark         \\\cline{2-\ncols}
%                        &$\fcAct$                   &ReLU                   &ReLU                   &ReLU           \\\hline
%\multirow{1}{*}{HEAD}   &$\headAct$                 &ReLU                   &ReLU                   &ReLU           \\\hline
%    
%    \end{tabular}
%\end{table}
%
%%https://en.wikipedia.org/wiki/Multiply%E2%80%93accumulate_operation
%%https://ai.stackexchange.com/questions/23482/are-mult-adds-and-flops-equivalent
%%https://github.com/TylerYep/torchinfo
%
%Table \ref{tab:ann_module_variants_nparams}
%shows the number of trainable and non-trainable parameters 
%as well as multiply-accumulate operations.
%
%
%For each variant, the num
%\begin{table}[h]
%    \caption{ANN module variants: 
%        number of trainable and non-trainable parameters 
%        and number of multiply-accumulate operations\label{tab:ann_module_variants_nparams}}
%    \centering
%    \begin{tabular}{|l|l|r|r|r|} \hline
%                        &\#                     &Baseline       &Baseline+      &Sequential \\\hline\hline
%\multirow{3}{*}{CNN}    &Trainables             &               &0              &0          \\\cline{2-\ncols}
%                        &Non-trainables         &               &11,176,512     &11,689,512 \\\cline{2-\ncols}
%                        &MAC Operations         &               &1,408,910,720  &           \\\hline
%\multirow{3}{*}{CAT}    &Trainables             &0              &0              &0          \\\cline{2-\ncols}
%                        &Non-trainables         &0              &0              &0          \\\cline{2-\ncols}
%                        &MAC Operations         &0              &0              &0          \\\hline                        
%\multirow{3}{*}{GRU}    &Trainables             &0              &0              &           \\\cline{2-\ncols}
%                        &Non-trainables         &0              &0              &           \\\cline{2-\ncols}
%                        &MAC Operations         &0              &0              &           \\\hline
%\multirow{3}{*}{FC}     &Trainables             &               &41,664         &0          \\\cline{2-\ncols}
%                        &Non-trainables         &               &0              &0          \\\cline{2-\ncols}
%                        &MAC Operations         &               &41,664         &0          \\\hline                        
%\multirow{3}{*}{HEAD}   &Trainables             &               &195            &           \\\cline{2-\ncols}
%                        &Non-trainables         &               &0              &           \\\cline{2-\ncols}
%                        &MAC Operations         &               &195            &           \\\hline\hline
%\multirow{3}{*}{Total}  &Trainables             &               &41,859         &           \\\cline{2-\ncols}
%                        &Non-trainables         &               &11,176,512     &           \\\cline{2-\ncols}
%                        &MAC Operations         &               &1,408,952,579  &           \\\hline
%
%%        CNN &n/a&\multicolumn{2}{|c|}{11,689,512}\\\hline
%%        GRU &\ref{eq:gru_param}&0&28,704\\\hline
%%        FC  &\ref{eq:fc_param}&262,144&0\\\hline
%%        HEAD&\ref{eq:head_param}&1,536&51\\\hline\hline
%%        Total&n/a&11,953,192&11,718,267\\\hline
%    \end{tabular}
%\end{table}

\section{Imitation Learning Process} \label{sec:training}
The ANN module of the autonomous navigation method 
must first learn to make meaningful navigation decisions.
In this thesis, as well as in the baseline work,
this task is viewed as an imitation learning problem.
The goal is that the ANN module learns to mimic
the navigation decision-making demonstrated by the expert system
of section \ref{sec:expert_system}.
The problem is addressed with dataset aggregation,
which is a type of interactive direct policy learning
(see section \ref{sec:imitation_learning}).
In the learning process, 
rollouts to generate additional training data 
alternate with supervised trainings of the ANN module on the aggregated dataset.
During a rollout, the drone navigates through a racetrack
based on the navigation decisions of the ANN module.
Whenever the ANN module makes a navigation decision 
that would cause the drone to deviate too far from the
expert's global trajectory through the racetrack, 
the interactive expert system intervenes 
and provides an expert navigation decision that is executed instead.
Also, 
a training sample labeled with the expert navigation decision 
is added to the training dataset 
so that, during training, the ANN module can learn from the mistakes made
during rollout.


The user specifies the learning configuration (see table \ref{tab:learn_config})
for the individual ANN module variant, 
which includes the rollout and the training configuration.
The rollout configuration comprises 
a set $\mathcal{S}$ of simulation configurations 
(see table \ref{tab:sim_config_opts}),
a set $\mathcal{V}$ of maximum drone speeds 
(see equ. \ref{eq:planning_des_speed})
and a set $\mathcal{E}$ of pairs of 
margins and thresholds for the expert intervention share
(hereafter referred to as margin-threshold pairs).
A margin determines the
distance of the drone from the global trajectory
above which the expert intervenes.
The threshold determines 
the share of expert navigation decisions 
in the total navigation decisions of a rollout, 
below which a rollout configuration is considered sufficiently learned.
The training configuration comprises 
the sequence length of the training samples aggregated during rollout
(which must be one if the individual ANN module is not recurrent),
the number of epochs after each rollout,
the batch size,
the loss function,
the optimizer type and the scheduling of the learning rate.
\begin{table}[h]
    \caption{Learning configuration options
    \label{tab:learn_config}}
    \centering
    \begin{tabular}{|c|c|c|} 
        \hline
        \multirow{9}{*}{Learning} 
        &\multirow{3}{*}{Rollout}   
        &Simulation configurations $\mathcal{S}$
        \\\cline{3-3}
        &
        &Max. drone speeds $\mathcal{V}$
        \\\cline{3-3}
        &
        &Margin-threshold pairs $\mathcal{E}$
        \\\cline{2-3}
        &\multirow{6}{*}{Training}   
        &Sequence length $\seqLen$
        \\\cline{3-3}
        &
        &Number of Epochs $\num[\user]{\text{epoch}}{}{}{}$
        \\\cline{3-3}
        &
        &Batch size $\batchSize$
        \\\cline{3-3}
        &
        &Loss
        \\\cline{3-3}
        &
        &Optimizer
        \\\cline{3-3}
        &
        &Learning rate
        \\\hline
    \end{tabular}
\end{table}


In detail, the learning process proceeds in the following steps.
\begin{itemize}
    \item For every margin-threshold pair $(M,T)$ in $\mathcal{E}$
    \item For every simulation configuration $S$ in $\mathcal{S}$
    \item For every maximum drone speed $V$ in $\mathcal{V}$
\end{itemize}
\begin{enumerate}
    \item Process and load $S$ in the simulation.
    \item Set the maximum drone speed $\speed[\user]{\drone}{\mxm}{}{} = v$
    of the planning module.
    \item Compute the expert's global trajectory through the racetrack.
    \item Roll out the ANN module with the interactive expert system
    for one round on the racetrack.
    At the user-specified main frequency $\freq[\user]{\main}{}{}{}$, 
    the following steps are taken.
    \begin{enumerate}
        \item The latest data from the onboard sensors is preprocessed
        to a single (non-sequential) input.
        (Which sensor data is included depends on the configuration of the individual ANN module.)
        \item The ANN module processes the single input
        to make a navigation decision. 
        (If the individual ANN module is recurrent, it can still make temporal connections
        because the single inputs incoming at the frequency $\freq[\user]{\main}{}{}{}$
        constitute a time series.)
        \item The planning module computes the local trajectory for the ANN navigation decision.
        \item If the end position of the local trajectory 
        is more distant from the expert's global trajectory than $M$:
        %the expert system intervenes by demonstrating a navigation decision,
        %whereupon the planner recomputes the local trajectory.
        \begin{enumerate}
            \item The expert system intervenes by making a navigation decision
            based on its knowledge.
            \item The planning module re-computes the local trajectory for the expert navigation decision.
        \end{enumerate}
        \item The local trajectory is forwarded to the control stack,
        which tracks it at a higher frequency than $\freq[\user]{\main}{}{}{}$.
    \end{enumerate}
    \item For every expert intervention of the latest rollout, 
    add a sample to the training dataset.
    A sample comprises an expert navigation decision as a label
    and the corresponding sequence of inputs
    for the individual ANN module variant.
    The sequence starts $\seqLen$ time steps 
    of duration $1/\freq[\user]{\main}{}{}{}$ 
    back in time and
    ends at the time step where
    the expert made the navigation decision.
    Record the share of the expert navigation decisions 
    in the total (expert and ANN) navigation decisions made during the rollout.
    \item Train the ANN module on the 
    aggregated training dataset with supervised learning.
    The number of epochs $\num[\user]{\text{epoch}}{}{}{}$,
    the batch size $\batchSize$,
    the loss function, the optimizer and the learning rate scheduling
    are specified in the training configuration.
    (For a recurrent ANN module, the samples of the training dataset
    are usually sequential. The ANN module then operates in many-to-one mode,
    whereby only the navigation decision from the processing of the last input 
    of the input sequence is used to calculate the loss.)
    \item If the recorded expert intervention share (from step 5) is greater
    than $T$, go back to step 1. Else the current 
    $(M,T)$-$S$-$V$ combination in the rollout configuration
    is considered as sufficiently learned by the ANN module.
\end{enumerate}

\section{Race Tests}
After an ANN module variant completed the imitation learning process,
its race performance is tested.
To do this, the ANN module variant is rolled out
with the expert system deactivated.
From records made during the rollout,
the variant's race performance is evaluated.


The user specifies the testing configuration
(see table \ref{tab:test_config}),
which includes a set of simulation configurations,
a set of maximum drone speeds,
and the number $\num[\user]{\text{rep}}{}{}{}$ of rollout repetitions for a given
combination of simulation configuration and maximum drone speed.
In order to ensure comparability of the race performance
of different ANN module variants while also using randomized racetracks,
$\num[\user]{\text{rep}}{}{}{}$ randomized racetracks are pre-computed 
for every possible simulation configuration 
(see table \ref{tab:sim_config_opts}).
\begin{table}[h]
    \caption{Testing configuration options
    \label{tab:test_config}}
    \centering
    \begin{tabular}{|c|c|} 
        \hline
        \multirow{3}{*}{Testing}   
        &Simulation configurations $\mathcal{S}$
        \\\cline{2-2}
        &Max. drone speeds $\mathcal{V}$
        \\\cline{2-2}
        &number of repetitions $\num[\user]{\text{rep}}{}{}{}$
        \\\hline
    \end{tabular}
\end{table}

In detail, the race tests are conducted as follows.
\begin{itemize}
    \item For every simulation configuration $S$ in $\mathcal{S}$
    \item For every maximum drone speed $V$ in $\mathcal{V}$
    \item For every repetition $N$ in $\mathcal{N}$
\end{itemize}
\begin{enumerate}
    \item Load $S$ with the $N$-th pre-computed racetrack for $S$ in the simulation.
    \item Set the maximum drone speed $\speed[\user]{\drone}{\mxm}{}{} = v$
    of the planning module.
    \item Roll out the ANN module for one round on the racetrack.
    At the user-specified main frequency $\freq[\user]{\main}{}{}{}$, 
    the following steps are taken.
    \begin{enumerate}
        \item Record the time-stamped position of the drone.
        \item The latest data from the onboard sensors is preprocessed
        to a single (non-sequential) input.
        (Which sensor data is included depends on the configuration of the individual ANN module.)
        \item The ANN module processes the single input
        to make a navigation decision. 
        (If the individual ANN module is recurrent, it can still make temporal connections
        because the single inputs incoming at the frequency $\freq[\user]{\main}{}{}{}$
        constitute a time series.)
        \item The planning module computes the local trajectory for the ANN navigation decision.
        \item The local trajectory is forwarded to the control stack,
        which tracks it at a higher frequency than $\freq[\user]{\main}{}{}{}$.
    \end{enumerate}
    \item Record if the drone, during the latest rollout, 
    completed the racetrack
    by traversing all gates without crashing. 
\end{enumerate}
The recordings allow the race performance 
of an ANN module variant to be evaluated.
On the basis of the racetrack completion records,
a variant's racetrack completion share
on a set of simulation configurations 
depending on the maximum drone speed
can be calculated.
The racetrack completion share quantifies
the robustness of a variant's navigation decision-making 
for a given setup.
The time-stamped drone position records of the rollouts
reproduce the flight trajectories induced by a variant.
The optimality with respect to jerk and snap
of these trajectories and therewith the 
variant's navigation decision-making 
can be quantified
with the loss functions of the optimization problem formulations
of the global and the local trajectory
(see equ. \ref{eq:glo_traj_opt_prob} and \ref{eq:loc_traj_opt_prob}).









\section{Design of Experiment 1}
Experiment 1 studies the
race performance of 
two feedforward and three recurrent ANN module variants 
on the randomized figure-8 racetrack 
in a single simulation environment.
Table \ref{tab:e1_config} shows the
configuration of experiment 1,
which includes the ANN module configuration
and the rollout and training configuration 
of the imitation learning process
for all variants examined.
A variant's ANN module configuration
determines its number of trainable parameters and 
multiply-accumulate (MAC) operations at a single inference.
Table \ref{tab:exp1_nums} shows these
numbers
obtained with 
torchinfo\footnote{\url{https://github.com/TylerYep/torchinfo}, accessed on \today}
for all variants examined.
A variant's number of trainable parameters
determines its degree of freedom to fit the aggregate training data
and, thus,
can correlate with 
how well the variant performs at training
and eventually at race.
For this reason, the numbers of trainable parameters 
are taken into account
when comparing the performance of the variants examined.
Furthermore, it has a great impact on
how memory- and time-consuming the variant's training is.
A variant's number of MAC operations 
measures the computing effort of a single inference
and, thus, has a great impact on the inference time
on a computing platform.
As drones are limited in computing power,
a variant's inference time 
is critical at race when 
navigation decisions
must be made at a relatively high frequency.
However, this experiment
can only list the MAC numbers of the variants examined
without further investigations on the inference time,
because the experiments in this thesis
could only be conducted in simulation on a desktop computer.


%\providecommand{\ncols}{}\renewcommand{\ncols}{8}
%\providecommand{\wcols}{}\renewcommand{\wcols}{1.3cm}
%\begin{table}[h]
%    \caption{ANN Module Variants of Experiment 1\label{tab:e1_ann_config}}
%    \centering
%    \begin{tabular}{|c|c|c|p{\wcols}|p{\wcols}|p{\wcols}|p{\wcols}|p{\wcols}|} 
%        \cline{4-\ncols}
%        \multicolumn{3}{c|}{}
%        &\multicolumn{2}{c|}{Feedforward}
%        &\multicolumn{3}{c|}{Recurrent}
%        \\\cline{4-\ncols}
%        \multicolumn{3}{c|}{}
%        &F1
%        &F2
%        &R1
%        &R2
%        &R3
%        \\\hline
%        %
%        \multirow{14}{*}{\rotcell{ANN}}
%        &\multirow{4}{*}{CNN}
%        &Input
%        &\multicolumn{5}{c|}{240x160 RGB}
%        \\\cline{3-\ncols}
%        %
%        &&Model
%        &Resnet8
%        &\multicolumn{4}{c|}{Resnet14}
%        \\\cline{3-\ncols}
%        %
%        &&Pretrained
%        &\multicolumn{4}{c|}{No}
%        &Yes
%        \\\cline{3-\ncols}
%        %
%        &&Trainable
%        &\multicolumn{4}{c|}{Yes}
%        &Partly
%        \\\cline{2-\ncols}
%        %
%        &\multirow{1}{*}{CAT}
%        &Opt. Input
%        &\multicolumn{3}{c|}{None}
%        &All
%        &None
%        \\\cline{2-\ncols}
%        %
%        &\multirow{3}{*}{GRU}
%        &\# Layers
%        &\multicolumn{2}{c|}{\multirow{3}{*}{None}}
%        &\multicolumn{3}{c|}{3}
%        \\\cline{3-3}\cline{6-\ncols}
%        %
%        &&Hidden size
%        &\multicolumn{2}{c|}{}
%        &\multicolumn{3}{c|}{64}
%        \\\cline{3-3}\cline{6-\ncols}
%        %
%        &&Dropout
%        &\multicolumn{2}{c|}{}
%        &\multicolumn{3}{c|}{0.00346}
%        \\\cline{2-\ncols}
%        %
%        &\multirow{4}{*}{FC}
%        &\# Layers
%        &\multicolumn{2}{c|}{3}
%        &\multicolumn{3}{c|}{\multirow{4}{*}{None}}
%        \\\cline{3-5}
%        %
%        &&Width
%        &\multicolumn{2}{c|}{256}
%        &\multicolumn{3}{c|}{}
%        \\\cline{3-5}
%        %
%        &&dropout
%        &\multicolumn{2}{c|}{0.206299}
%        &\multicolumn{3}{c|}{}
%        \\\cline{3-5}
%        %
%        &&Activation
%        &\multicolumn{2}{c|}{ReLU}
%        &\multicolumn{3}{c|}{}
%        \\\cline{2-\ncols}
%        %
%        &\multirow{2}{*}{HEAD}
%        &Activation
%        &\multicolumn{5}{c|}{ReLU}
%        \\\cline{3-\ncols}
%        &&Output
%        &\multicolumn{5}{c|}{Navigation decision}
%        \\\hline
%    \end{tabular}
%\end{table}
\providecommand{\ncols}{}\renewcommand{\ncols}{9}
\providecommand{\wcols}{}\renewcommand{\wcols}{1.3cm}
\definecolor{light-gray}{gray}{0.90}
\begin{table}[h]
    \caption{Configuration of Experiment 1
    \label{tab:e1_config}}
    \centering
    \begin{tabular}{|c|c|c|c|p{\wcols}|p{\wcols}|p{\wcols}|p{\wcols}|p{\wcols}|} 
        \cline{5-9}
        \multicolumn{4}{c|}{}
        &\multicolumn{2}{c|}{Feedforward}
        &\multicolumn{3}{c|}{Recurrent}
        \\\cline{5-9}
        \multicolumn{4}{c|}{}
        &F1
        &F2
        &R1
        &R2
        &R3
        \\\hline
        %
        \multicolumn{2}{|c|}{\multirow{14}{*}{\rotcell{ANN}}}
        &\multirow{4}{*}{CNN}
        &Input
        &\multicolumn{5}{c|}{240x160 RGB}
        \\\cline{4-\ncols}
        %
        \multicolumn{2}{|c|}{}
        &&Model
        &Resnet8
        &\multicolumn{4}{c|}{Resnet14}
        \\\cline{4-\ncols}
        %
        \multicolumn{2}{|c|}{}
        &&Pretrained
        &\multicolumn{4}{c|}{No}
        &Yes
        \\\cline{4-\ncols}
        %
        \multicolumn{2}{|c|}{}
        &&Trainable
        &\multicolumn{4}{c|}{Yes}
        &Partly
        \\\cline{3-\ncols}
        %
        \multicolumn{2}{|c|}{}
        &\multirow{1}{*}{CAT}
        &Opt. Input
        &\multicolumn{3}{c|}{None}
        &All
        &None
        \\\cline{3-\ncols}
        %
        \multicolumn{2}{|c|}{}
        &\multirow{3}{*}{GRU}
        &\# Layers
        &\multicolumn{2}{c|}{\multirow{3}{*}{None}}
        &\multicolumn{3}{c|}{3}
        \\\cline{4-4}\cline{7-\ncols}
        %
        \multicolumn{2}{|c|}{}
        &&Hidden size
        &\multicolumn{2}{c|}{}
        &\multicolumn{3}{c|}{64}
        \\\cline{4-4}\cline{7-\ncols}
        %
        \multicolumn{2}{|c|}{}
        &&Dropout
        &\multicolumn{2}{c|}{}
        &\multicolumn{3}{c|}{0.013767}
        \\\cline{3-\ncols}
        %
        \multicolumn{2}{|c|}{}
        &\multirow{4}{*}{FC}
        &\# Layers
        &\multicolumn{2}{c|}{3}
        &\multicolumn{3}{c|}{\multirow{4}{*}{None}}
        \\\cline{4-6}
        %
        \multicolumn{2}{|c|}{}
        &&Width
        &\multicolumn{2}{c|}{256}
        &\multicolumn{3}{c|}{}
        \\\cline{4-6}
        %
        \multicolumn{2}{|c|}{}
        &&Dropout
        &\multicolumn{2}{c|}{0.206299}
        &\multicolumn{3}{c|}{}
        \\\cline{4-6}
        %
        \multicolumn{2}{|c|}{}
        &&Activation
        &\multicolumn{2}{c|}{ReLU}
        &\multicolumn{3}{c|}{}
        \\\cline{3-\ncols}
        %
        \multicolumn{2}{|c|}{}
        &\multirow{2}{*}{HEAD}
        &Activation
        &\multicolumn{5}{c|}{ReLU}
        \\\cline{4-\ncols}
        \multicolumn{2}{|c|}{}
        &&Output
        &\multicolumn{5}{c|}{Navigation decision}
        \\\hline
        %
        \multirow{14}{*}{\rotcell{Learning}} 
        &
        \multirow{8}{*}{\rotcell{Rollout}}
        &\multirow{2}{*}{\shortstack{Environ-\\ments}}
        &Scenes
        &\multicolumn{5}{c|}{Spaceship interior}
        \\\cline{4-9}
        &&&Sites
        &\multicolumn{5}{c|}{A}
        \\\cline{3-9}
        &&\multirow{4}{*}{\shortstack{Race-\\tracks}}
        &Types
        &\multicolumn{5}{c|}{Figure-8}
        \\\cline{4-9}
        &&&Generations
        &\multicolumn{5}{c|}{Randomized}
        \\\cline{4-9}
        &&&Directions
        &\multicolumn{5}{c|}{Counterclockwise}
        \\\cline{4-9}
        &&&Gates
        &\multicolumn{5}{c|}{TUB-DAI, THU-DME}
        \\\cline{3-9}
        &
        &\multicolumn{2}{c|}{Max. drone speeds}
        &\multicolumn{5}{c|}{4, 5, 6, 7, 8, 9, 10 m/s}
        \\\cline{3-9}
        &
        &\multicolumn{2}{c|}{Margin-threshold}
        &\multicolumn{5}{c|}{(0.5, 10), (0.75, 5), (1.0 m, 1\%)}
        \\\cline{2-9}        
        &
        \multirow{6}{*}{\rotcell{Training}}
        %\multirow{6}{*}{Training}   
        &\multicolumn{2}{c|}{Sequence length}
        &\multicolumn{2}{c|}{1}
        &\multicolumn{3}{c|}{25}
        \\\cline{3-9}
        &
        &\multicolumn{2}{c|}{\# Epochs}
        &\multicolumn{2}{c|}{10}
        &\multicolumn{3}{c|}{3}
        \\\cline{3-9}
        &
        &\multicolumn{2}{c|}{Batch size}
        &256
        &32
        &\multicolumn{3}{c|}{8}
        \\\cline{3-9}
        &
        &\multicolumn{2}{c|}{Loss}
        &\multicolumn{5}{c|}{SmoothL1Loss}
        \\\cline{3-9}
        &
        &\multicolumn{2}{c|}{Optimizer}
        &\multicolumn{5}{c|}{ADAM}
        \\\cline{3-9}
        &
        &\multicolumn{2}{c|}{Learning rate}
        &\multicolumn{5}{c|}{Exponential: $10^{-4}\cdot 0.95^\text{epoch}$}
        \\\hline
        %\multicolumn{2}{|c|}{\multirow{8}{*}{\rotcell{Testing}}}
        %&\multirow{2}{*}{\shortstack{Environ-\\ments}}
        %&Scenes
        %&\multicolumn{5}{c|}{Spaceship interior}
        %\\\cline{4-9}
        %\multicolumn{2}{|c|}{}
        %&&Sites
        %&\multicolumn{5}{c|}{A}
        %\\\cline{3-9}
        %\multicolumn{2}{|c|}{}
        %&\multirow{4}{*}{\shortstack{Race-\\tracks}}
        %&Types
        %&\multicolumn{5}{c|}{Figure-8}
        %\\\cline{4-9}
        %\multicolumn{2}{|c|}{}
        %&&Generations
        %&\multicolumn{5}{c|}{Randomized}
        %\\\cline{4-9}
        %\multicolumn{2}{|c|}{}
        %&&Directions
        %&\multicolumn{5}{c|}{Counterclockwise}
        %\\\cline{4-9}
        %\multicolumn{2}{|c|}{}
        %&&Gates
        %&\multicolumn{5}{c|}{TUB-DAI, THU-DME}
        %\\\cline{3-9}
        %\multicolumn{2}{|c|}{}
        %&\multicolumn{2}{c|}{Max. drone speeds}
        %&\multicolumn{5}{c|}{4, 5, 6, 7, 8, 9, 10 m/s}
        %\\\hline
    \end{tabular}
\end{table}

\providecommand{\ncols}{}\renewcommand{\ncols}{7}
\begin{table}[h]
    \caption[
        Trainable parameters and MAC operations of experiment 1
    ]{
        Numbers (in the format $m\text{e}n = m\times 10^n$) of trainable parameters (TP)
        and multiply-accumulate operations (MAC)
        of the ANN module variants of experiment 1.
        For R3, the table does not reflect 
        the negligible number of single trainings 
        in the learning process
        where the CNN parameters are momentarily trainable.
        \label{tab:exp1_nums}}        
    \centering
    \begin{tabular}{|c|c|r|r|r|r|r|} 
        \hline
        ANN
        &\#
        &F1
        &F2
        &R1
        &R2
        &R3
        \\\hline\hline
        %
        \multirow{2}{*}{CNN}
        &TP
        &309e3
        &2.78e6
        &2.78e6
        &2.78e6
        &0
        \\\cline{2-\ncols}
        %
        %&NTP
        %&0
        %&0
        %&0
        %&0
        %&2.78e6
        %\\\cline{2-\ncols}
        %
        &MAC
        &52.9e6
        &1.07e9
        &1.07e9
        &1.07e9
        &1.07e9
        \\\hline
        %
        %\multirow{3}{*}{CAT}
        %&TP
        %&0
        %&0
        %&0
        %&0
        %&0
        %\\\cline{2-\ncols}
        %%
        %&NTP
        %&0
        %&0
        %&0
        %&0
        %&0
        %\\\cline{2-\ncols}
        %%
        %&MAC
        %&0
        %&0
        %&0
        %&0
        %&0
        %\\\hline
        %
        \multirow{2}{*}{GRU}
        &TP
        &0
        &0
        &112e3
        &113e3
        &112e3
        \\\cline{2-\ncols}
        %
        %&NTP
        %&0
        %&0
        %&0
        %&0
        %&0
        %\\\cline{2-\ncols}
        %
        &MAC
        &0
        &0
        &112e3
        &112e3
        &112e3
        \\\hline
        %
        \multirow{2}{*}{FC}
        &TP
        &164e3
        &197e3
        &0
        &0
        &0
        \\\cline{2-\ncols}
        %
        %&NTP
        %&0
        %&0
        %&0
        %&0
        %&0
        %\\\cline{2-\ncols}
        %
        &MAC
        &164e3
        &197e3
        &0
        &0
        &0
        \\\hline
        %
        \multirow{2}{*}{HEAD}
        &TP
        &771
        &771
        &195
        &195
        &195
        \\\cline{2-\ncols}
        %
        %&NTP
        %&0
        %&0
        %&0
        %&0
        %&0
        %\\\cline{2-\ncols}
        %
        &MAC
        &771
        &771
        &195
        &195
        &195
        \\\hline\hline
        %
        \multirow{2}{*}{Total}
        &TP
        &474e3
        &2.98e6
        &2.89e6
        &2.90e6
        &112e3
        \\\cline{2-\ncols}
        %
        %&NTP
        %&0
        %&0
        %&0
        %&0
        %&2.78e6
        %\\\cline{2-\ncols}
        %
        &MAC
        &53.1e6
        &1.07e9
        &1.07e9
        &1.07e9
        &1.07e9
        \\\hline
    \end{tabular}
\end{table}

Common to all ANN module variants is that
first, the CNN submodule inputs 240x160 preprocessed RGB images
from the drone's onboard camera.
Second, the HEAD submodule is a
ReLU-activated, fully-connected layer 
that outputs navigation decisions.
And third, the input sequences of the training samples 
are processed with a dropout with a 
resultant dropout probability of 50 \%.
For a variant that during inference applies dropout $x$ times 
with the same dropout probability
and that trains on samples with the input sequence length $y$, 
the dropout probability at a single application is
calculated with
\begin{align} \label{eq:single_dropout}
    \probability = 1 -\sqrt[xy]{0.5}.
\end{align}


The two feedforward variants 
are characterized by 
deactivated GRU submodule and an activated FC submodule,
which consists of three
ReLU-activated, dropout-subjected, fully-connected layers
with a width of 256 neurons.
For a resultant dropout probability of 50\%
when processing input sequences of length 1,
equation \ref{eq:single_dropout} yields the dropout probability 
at a single application of approximately 20.63\%.
The first feedforward variant (F1)
is a slightly extended version of the ANN 
deployed in the baseline autonomous navigation method 
of Kaufmann et al. \cite{Kaufmann2018}.
The CNN submodule of F1 is,
like the baseline, 
implemented with an 8-layer Resnet \cite{He2015}.
Unlike the baseline, its FC submodule 
has three instead of one layer.
This extension adjusts F1
to the other examined variants in terms of
the number of trainable parameters of the FC/GRU submodule
in order to increase the variants' comparability.
The second feedforward variant (F2) differs from F1
only in the CNN submodule
as it uses a 14-layer instead of an 8-layer Resnet.
Preliminary experiments on Resnet
implementations of different complexity
(not documented)
suggest that more complex Resnets 
than the one used in the baseline work
yield significantly better results.
The Resnet14 was chosen for F2
because it represents a good compromise
in terms of the increase in trainable parameters,
thus keeping the variant's
memory occupation 
and training duration within tolerable limits.
Nonetheless, using the 8-layer or the 14-layer Resnet
has by far the largest impact on the 
total number of both parameters and MAC operations of a variant.
Compared to Resnet8, 
Resnet14 has approximately 
9 times more parameters and 
performs approximately 20 times more MAC operations
at a single inference.
F1 is the only variant using Resnet8
and has thus by far the lowest MAC number.
This experiment compares F1 and F2 
to investigate whether the higher CNN complexity of F2 
is reflected in the race performance of the variant.


The three recurrent variants
are characterized by a deactivated FC submodule and 
an activated GRU submodule,
which consists of three layers
with a hidden size of 64,
of which the second and the third layer
are subjected to dropout.
For a resultant dropout probability of 50\%
when processing input sequences of length 25,
equation \ref{eq:single_dropout} yields the dropout probability 
at a single application of approximately 1.38\%.
Care was taken to ensure that the GRU submodule 
of the three recurrent variants has fewer trainable parameters
than the FC submodule of the two feedforward variants,
in order to rule out the possibility 
that the recurrent variants perform better only 
because of a higher number of trainable parameters.
All three variants use the Resnet14 
because F2 performs significantly stronger than F1
(see results in section \ref{results}).
%\textbf{recurrent with resnet8 not converged}
The first recurrent variant (R1)
is the recurrent equivalent of F2.
The comparison of F2 and R1, thus,
aims to investigate the impact of the GRU submodule's 
temporal comprehension on the race performance of a variant.
The second recurrent variant (R2) differs 
from R1 with respect to the CAT submodule.
While the CAT submodule for R1 is deactivated,
for R2, it inputs
all available optional inputs.
The comparison of R1 and R2, thus,
aims to investigate the impact of 
using the optional inputs
within a variant's navigation decision-making
on the variant's race performance.
The third recurrent variant (R3) differs 
from R1 with respect to the CNN submodule.
While the CNN submodule for R1 is trainable and not pretrained,
for R2, it is pretrained and only partly trainable.
%\textbf{imagenet clasifier not converged}
The pretraining of the CNN submodule
was carried out with a preliminary final layer
on training data from 
preliminary experiments (not documented).
The CNN is only trainable at the single trainings
whenever a margin-threshold pair is completed in the learning process.
As a result, R3 has by far the lowest number of trainable parameters
for most trainings, whereby 
the learning of R3 can be highly accelerated.
The comparison of R1 and R2, thus,
aims to investigate 
whether this shortcut
has a tolerable impact on a
variant's race performance.

To summarize the relation of the ANN module configurations of the variants examined: 
F1 represents the feedforward ANN of the baseline work.
F2 integrates a 14-layer instead of an 8-layer Resnet.
R1 is the recurrent counterpart of F2.
R2 additionally uses the optional inputs.
The CNN submodule of R3 is pretrained  
and trainable only partly in time.

The rollout configuration of the learning process
is the same for all variants examined.
The variants learn to navigate through 
the randomized, counterclockwise figure-8 racetrack
built with the TUB-DAI or THU-DME gate type.
The racetrack is thereby located in
site A of the spaceship interior scene.
This limitation to a single simulation environment
is motivated by the 
high time expenditure of the imitation learning process.
As a result,
this experiment can only compare the variants 
in terms of their ability to generalize 
to the randomized figure-8 racetrack
located in a single, fixed simulation environment
and does not provide insights 
regarding the generalization to simulation environments 
unseen in the learning process.
The maximum drone speeds of the planning module
during the learning rollouts
range from 4 to 10 m/s in 1 m/s steps.
The learning at different speeds is motivated
by the fact that the maximum drone speed 
influences the state distribution of a variant's rollout.
For the intervening expert system, 
there are three margin-threshold pairs, 
with the margins becoming wider 
and the thresholds becoming more stringent.
To complete the learning on a rollout configuration,
the variant must perform a rollout 
with less than 10/5/1\% expert interventions
that are triggered whenever the variant
would navigate the drone further than 0.5/0.75/1.0 m
from the expert's global trajectory.

With respect to the training configuration of the learning process,
all variants share that they 
determine loss with
the standard 
SmoothL1Loss\footnote{\url{https://pytorch.org/docs/stable/nn.html}, accessed on \today}
PyTorch implementation
and update the variants' trainable parameters accordingly 
with the standard 
ADAM\footnote{\url{https://pytorch.org/docs/stable/optim.html}, accessed on \today}
PyTorch implementation,
whereby the learning rate is exponentially scheduled
with the initial value of $10^{-4}$ for each training and a decay of 
95\% per epoch.
Moreover, all variants share that the batch size 
is set to the maximum value containable by
the GPU memory of my desktop computer.
The feedforward and the recurrent variants differ 
by the aggregate training samples
and the number of epochs per training.
While for the feedforward variants,
the inputs of the samples are non-sequential,
for the recurrent variants,
they have a sequence length of 25.
As a result, the training epochs of the
recurrent variants consume significantly more time.
However, preliminary experiments 
(not documented here)
suggested that these recurrent training epochs 
also lower the loss more effectively.
Therefore, the number of epochs per training
is set to 10 and 3 for the feedforward
and the recurrent variants, respectively.

After the learning process, the variants are tested.
Table \ref{tab:e1_test_config} shows 
the configuration of the race test.
For testing, the variants roll out on the same 
simulation configuration
(environment and racetrack)
with the same maximum drone speeds as for learning.
For every combination in the testing configuration,
each variant rolls out 10 times.
\begin{table}[h]
    \caption{Testing configuration for experiment 1
    \label{tab:e1_test_config}}
    \centering
    \begin{tabular}{|c|c|c|c|} 
        \hline
        \multirow{8}{*}{\rotcell{Testing}}   
        &\multirow{2}{*}{\shortstack{Environ-\\ments}}
        &Scenes
        &\multicolumn{1}{c|}{Spaceship interior}
        \\\cline{3-4}
        &&Sites
        &\multicolumn{1}{c|}{A}
        \\\cline{2-4}
        &\multirow{4}{*}{\shortstack{Race-\\tracks}}
        &Types
        &\multicolumn{1}{c|}{Figure-8}
        \\\cline{3-4}
        &&Generations
        &\multicolumn{1}{c|}{Randomized}
        \\\cline{3-4}
        &&Directions
        &\multicolumn{1}{c|}{Counterclockwise}
        \\\cline{3-4}
        &&Gates
        &\multicolumn{1}{c|}{TUB-DAI, THU-DME}
        \\\cline{2-4}
        &\multicolumn{2}{c|}{Max. drone speeds}
        &\multicolumn{1}{c|}{4, 5, 6, 7, 8, 9, 10 m/s}
        \\\cline{2-4}
        &\multicolumn{2}{c|}{Number of repetitions}
        &\multicolumn{1}{c|}{10}
        \\\hline
    \end{tabular}
\end{table}







\section{Design of Experiment 2}
Experiment 2 takes 
the ANN module variant R1 
of experiment 1 (see table \ref{tab:e1_config})
as a starting point
to study the impact of the depth
of the GRU submodule on a variant's
race performance.
The starting point R1 exhibits the best race performance
among all variants examined in experiment 1
(see section \ref{results}).
The following briefly recalls 
the configuration of R1 in experiment 1.

R1 integrates
a trainable, not pretrained 14-layer Resnet, 
a three-layer GRU with a hidden size of 64
and a resultant dropout probability of 50\%
and a final, ReLU-activated, fully-connected layer 
in order to map 240x160 preprocessed RGB images
from the drone's onboard camera
to navigation decisions forwarded to the planning module.
The variant rolls out on the randomized figure-8 racetrack
in a single simulation environment
for maximum drone speeds of $4,5,\dots,10$ m/s.
Thereby, a training sample of sequence length 25 
is generated whenever the expert system intervenes
to correct a navigation decision that would navigate
the drone out of the current margin.
After each rollout, R1 trains on
the aggregate training dataset 
for 3 epochs with supervised learning.



Experiment 2 studies the race performance
of five ANN module variants
that are configured like R1
(see table \ref{tab:e1_config})
except that the GRU submodule has
1, 2, 3 (this is the original number of R2), 5, or 10 layers
and the dropout at a single application
has a probability of approximately
none (by design, the first layer applies no dropout), 
2.73, 1.38, 0.69 or 0.31\%
, respectively,
in order to maintain
a resultant dropout probability of 50\%
(see equ. \ref{eq:single_dropout}).
A variant examined in this experiment 
with $L$ GRU layers
of a hidden size of $H$
is referred to as R1-$L$x$H$.

The five variants are trained for
200 epochs on 
the final training dataset of R1
which contains 18k samples collected in 114 rollouts
of the learning process.
Thereafter, the variants perform
race tests with the same
configuration as R1 (see table \ref{tab:e1_test_config}).





\section{Design of Experiment 3}
Experiment 3 studies the race performance of a
feedforward and a recurrent ANN module variant
on the randomized gap racetrack in several
simulation environments.
Table \ref{tab:e3_config} shows the configuration of experiment 3,
including the ANN module configuration
and the learning configuration.
Table \ref{tab:exp3_nums} shows the number of trainable parameters
and MAC operations for both examined variants.

\providecommand{\ncols}{}\renewcommand{\ncols}{6}
\providecommand{\wcols}{}\renewcommand{\wcols}{2.7cm}
\definecolor{light-gray}{gray}{0.90}
\begin{table}[h]
    \caption{Configuration of Experiment 3
    \label{tab:e3_config}}
    \centering
    \begin{tabular}{|c|c|c|c|p{\wcols}|p{\wcols}|} 
        \cline{5-\ncols}
        \multicolumn{4}{c|}{}
        &\multicolumn{1}{c|}{Feedforward}
        &\multicolumn{1}{c|}{Recurrent}
        \\\cline{5-\ncols}
        %
        \multicolumn{4}{c|}{}
        &E3F
        &E3R
        \\\hline
        %
        \multicolumn{2}{|c|}{\multirow{14}{*}{\rotcell{ANN}}}
        &\multirow{4}{*}{CNN}
        &Input
        &\multicolumn{2}{c|}{360x240 RGB}
        \\\cline{4-\ncols}
        %
        \multicolumn{2}{|c|}{}
        &&Model
        &\multicolumn{2}{c|}{Resnet18}
        \\\cline{4-\ncols}
        %
        \multicolumn{2}{|c|}{}
        &&Pretrained
        &\multicolumn{2}{c|}{No}
        \\\cline{4-\ncols}
        %
        \multicolumn{2}{|c|}{}
        &&Trainable
        &\multicolumn{2}{c|}{Yes}
        \\\cline{3-\ncols}
        %
        \multicolumn{2}{|c|}{}
        &\multirow{1}{*}{CAT}
        &Opt. Input
        &\multicolumn{2}{c|}{All}
        \\\cline{3-\ncols}
        %
        \multicolumn{2}{|c|}{}
        &\multirow{3}{*}{GRU}
        &\# Layers
        &\multicolumn{1}{c|}{\multirow{3}{*}{None}}
        &\multicolumn{1}{c|}{3}
        \\\cline{4-4}\cline{6-\ncols}
        %
        \multicolumn{2}{|c|}{}
        &&Hidden size
        &\multicolumn{1}{c|}{}
        &\multicolumn{1}{c|}{16}
        \\\cline{4-4}\cline{6-\ncols}
        %
        \multicolumn{2}{|c|}{}
        &&Dropout
        &\multicolumn{1}{c|}{}
        &\multicolumn{1}{c|}{0.109101}
        \\\cline{3-\ncols}
        %
        \multicolumn{2}{|c|}{}
        &\multirow{4}{*}{FC}
        &\# Layers
        &\multicolumn{1}{c|}{1}
        &\multicolumn{1}{c|}{\multirow{4}{*}{None}}
        \\\cline{4-5}
        %
        \multicolumn{2}{|c|}{}
        &&Width
        &\multicolumn{1}{c|}{512}
        &\multicolumn{1}{c|}{}
        \\\cline{4-5}
        %
        \multicolumn{2}{|c|}{}
        &&Dropout
        &\multicolumn{1}{c|}{0.5}
        &\multicolumn{1}{c|}{}
        \\\cline{4-5}
        %
        \multicolumn{2}{|c|}{}
        &&Activation
        &\multicolumn{1}{c|}{ReLU}
        &\multicolumn{1}{c|}{}
        \\\cline{3-\ncols}
        %
        \multicolumn{2}{|c|}{}
        &\multirow{2}{*}{HEAD}
        &Activation
        &\multicolumn{2}{c|}{ReLU}
        \\\cline{4-\ncols}
        \multicolumn{2}{|c|}{}
        &&Output
        &\multicolumn{2}{c|}{Navigation decision}
        \\\hline
        %
        \multirow{14}{*}{\rotcell{Learning}} 
        &
        \multirow{8}{*}{\rotcell{Rollout}}
        &\multirow{3}{*}{\shortstack{Environ-\\ments}}
        &\multirow{2}{*}{Scenes}
        %&\multicolumn{2}{c|}{Spaceship interior, destroyed city, industrial site, polygon city}
        &\multicolumn{2}{c|}{\multirow{2}{*}{\shortstack{Spaceship interior, destroyed city,\\industrial site, polygon city}}}
        \\&&&&\multicolumn{2}{c|}{}
        \\\cline{4-\ncols}
        &&&Sites
        &\multicolumn{2}{c|}{A, B, C}
        \\\cline{3-\ncols}
        &&\multirow{4}{*}{\shortstack{Race-\\tracks}}
        &Types
        &\multicolumn{2}{c|}{Gap}
        \\\cline{4-\ncols}
        &&&Generations
        &\multicolumn{2}{c|}{Randomized}
        \\\cline{4-\ncols}
        &&&Directions
        &\multicolumn{2}{c|}{Counterclockwise, Clockwise}
        \\\cline{4-\ncols}
        &&&Gates
        &\multicolumn{2}{c|}{TUB-DAI, THU-DME}
        \\\cline{3-\ncols}
        &
        &\multicolumn{2}{c|}{Max. drone speeds}
        &\multicolumn{2}{c|}{4, 6, 8 m/s}
        \\\cline{3-\ncols}
        &
        &\multicolumn{2}{c|}{Margin-threshold}
        &\multicolumn{2}{c|}{(0.7, 6), (0.5 m, 6\%)}
        \\\cline{2-\ncols}        
        &
        \multirow{6}{*}{\rotcell{Training}}
        %\multirow{6}{*}{Training}   
        &\multicolumn{2}{c|}{Sequence length}
        &\multicolumn{1}{c|}{1}
        &\multicolumn{1}{c|}{3}
        \\\cline{3-\ncols}
        &
        &\multicolumn{2}{c|}{\# Epochs}
        &\multicolumn{2}{c|}{5}
        \\\cline{3-\ncols}
        &
        &\multicolumn{2}{c|}{Batch size}
        &\multicolumn{1}{c|}{32}
        &\multicolumn{1}{c|}{16}
        \\\cline{3-\ncols}
        &
        &\multicolumn{2}{c|}{Loss}
        &\multicolumn{2}{c|}{SmoothL1Loss}
        \\\cline{3-\ncols}
        &
        &\multicolumn{2}{c|}{Optimizer}
        &\multicolumn{2}{c|}{ADAM}
        \\\cline{3-\ncols}
        &
        &\multicolumn{2}{c|}{Learning rate}
        &\multicolumn{2}{c|}{Exponential: $10^{-4}\cdot 0.99^\text{epoch}$}
        \\\hline
    \end{tabular}
\end{table}


\providecommand{\ncols}{}\renewcommand{\ncols}{4}
\begin{table}[h]
    \caption[
        Trainable parameters and MAC operations of experiment 3
    ]{
        Numbers (in the format $m\text{e}n = m\times 10^n$) of trainable parameters (TP)
        and multiply-accumulate operations (MAC)
        of the ANN module variants of experiment 3.
        \label{tab:exp3_nums}}        
    \centering
    \begin{tabular}{|c|c|r|r|} 
        \hline
        ANN
        &\#
        &E3F
        &E3R
        \\\hline
        %
        \multirow{2}{*}{CNN}
        &TP
        &\multicolumn{2}{c|}{11.2e6}
        \\\cline{2-\ncols}
        %
        &MAC
        &\multicolumn{2}{c|}{3.24e9}
        \\\hline
        %
        \multirow{2}{*}{GRU}
        &TP
        &\multirow{2}{*}{None}
        &29.1e3
        \\\cline{2-2}\cline{4-\ncols}
        %
        &MAC
        &
        &29.1e3
        \\\hline
        %
        \multirow{2}{*}{FC}
        &TP
        &267e3
        &\multirow{2}{*}{None}
        \\\cline{2-3}
        %
        &MAC
        &267e3
        &
        \\\hline
        %
        \multirow{2}{*}{HEAD}
        &TP
        &1.54e3
        &48
        \\\cline{2-\ncols}
        %
        &MAC
        &1.54e3
        &48
        \\\hline
        %
        \multirow{2}{*}{Total}
        &TP
        &11.4e6
        &11.2e6
        \\\cline{2-\ncols}
        %
        &MAC
        &\multicolumn{2}{c|}{3.24e9}
        \\\hline
    \end{tabular}
\end{table}

Both variants integrate a trainable,
not pretrained 18-layer Resnet
to process 360x240 RGB images,
the CAT submodule to input 
all available, optional inputs
and the ReLU activated HEAD submodule 
to output navigation decisions.
Moreover, both variants process a training sample 
input with a resultant dropout probability of 
50\% (see equ. \ref{eq:single_dropout}).

The feedforward variant (E3F)
is characterized by the deactivated GRU submodule
and the activated FC submodule,
which is a single, ReLU activated,
dropout-subjected, fully-connected layer with 512 neurons.
Therewith, 
E3F corresponds to the ANN design in the baseline work
with the Resnet8 extended to a Resnet18.
The recurrent variant (E3R)
is characterized by the deactivated FC submodule
and the activated GRU submodule,
which consists of three layers with a hidden size of 16, of
which the second and the third layer are subjected to dropout.

The Resnet18 dominates the numbers of trainable parameters
and (even more) MAC operations for both variants.
Nonetheless, care was taken that the
GRU submodule of E3R
has less trainable parameters
than the FC submodule of E3F
in order to rule out
the possibility that E3R performs 
better only because of a higher complexity.

The rollout configuration of the learning process 
is the same for both variants examined.
For a maximum drone speed of 
4, 6 and 8 m/s,
the variants learn to navigate 
through the randomized, counterclockwise 
and clockwise gap racetrack 
built with the TUB-DAI or THU-DME gate type,
which is located in all three sites of the scenes
spaceship interior, destroyed city,
industrial site and polygon city.
For the intervening expert system,
there are two margin-threshold pairs.
The first margin is wider than the second,
while the threshold remains to be 6\%.
%\textbf{compare with e1}


The training configuration of the learning process 
is partly the same for both variants.
Both are trained for 5 epochs 
with the SmoothL1Loss, the ADAM optimizer
and an exponentially scheduled learning rate.
The batch size for both variants 
is set to the maximum value containable by the GPU
memory of my desktop computer.
E3F trains on samples with non-sequential input,
while E3R trains on samples with an input sequence length
of 3.

Table \ref{tab:e3_test_config} shows the configuration for the race tests.
The variants roll out in the four scenes seen during learning
as well as the desert mountain scene unseen during learning.
Thereby, the maximum drone speed is set to 
4, 5, ..., 10 m/s, of which only 4, 6 and 8 m/s
were experienced during learning.
For every combination in the testing configuration,
each variant rolls out only once
due to the large number of combinations.

\begin{table}[h]
    \caption{Testing configuration for experiment 3
    \label{tab:e3_test_config}}
    \centering
    \begin{tabular}{|c|c|c|c|} 
        \hline
        \multirow{8}{*}{\rotcell{Testing}}   
        &\multirow{3}{*}{\shortstack{Environ-\\ments}}
        &\multirow{2}{*}{Scenes}
        &\multicolumn{1}{c|}{\multirow{2}{*}{\shortstack{Spaceship interior, destroyed city,\\industrial site, polygon city, desert mountain}}}
        \\&&&\multicolumn{1}{c|}{}
        \\\cline{3-4}
        &&Sites
        &\multicolumn{1}{c|}{A, B, C}
        \\\cline{2-4}
        &\multirow{4}{*}{\shortstack{Race-\\tracks}}
        &Types
        &\multicolumn{1}{c|}{Gap}
        \\\cline{3-4}
        &&Generations
        &\multicolumn{1}{c|}{Randomized}
        \\\cline{3-4}
        &&Directions
        &\multicolumn{1}{c|}{Counterclockwise, Clockwise}
        \\\cline{3-4}
        &&Gates
        &\multicolumn{1}{c|}{TUB-DAI, THU-DME}
        \\\cline{2-4}
        &\multicolumn{2}{c|}{Max. drone speeds}
        &\multicolumn{1}{c|}{4, 5, 6, 7, 8, 9, 10 m/s}
        \\\cline{2-4}
        &\multicolumn{2}{c|}{Number of repetitions}
        &\multicolumn{1}{c|}{1}
        \\\hline
    \end{tabular}
\end{table}





\section{Design of Experiment 4}
Experiment 4 takes the better performing
of both ANN module variant examined in experiment 3,
i.e., the recurrent variant E3R
(see table \ref{tab:e3_config}),
and its final, aggregated training dataset
as a starting point
for studying the impact of the 
input sequence length and the image size
of the training data
on the race performance of a recurrent variant.

The training dataset of E3R obtained in experiment 3
contains 40k samples 
whose input is a sequence of 
three pairs of a 360x240 RGB image 
and an optional input vector.
In experiment 4, 
the training dataset is rebuilt from the raw data
recorded during the learning process of E3R
with a varying input sequence length of 
2, 3, 5 and 10
and a varying RGB image size of 
240x160 and 360x240,
which yields eight different datasets.
Then, 
the eight variants
named 
E3R-2*240x160,
E3R-3*240x160,
E3R-5*240x160,
E3R-10*240x160,
E3R-2*360x240,
E3R-3*360x240 (the starting point),
E3R-5*360x240
and
E3R-10*360x240
train on these datasets.
The ANN modules of these eight variants
are configured like the starting point.
However, for a resultant dropout probability
of 50\%, the dropout probability
for a single dropout application of the GRU submodule
is adjusted by equation \ref{eq:single_dropout}.

Finally,
the variants perform
race tests with the same
configuration as E3R (see table \ref{tab:e3_test_config}).

%A variant examined in this experiment 
%with $L$ GRU layers
%of a hidden size of $H$
%is referred to as R1-$L$x$H$.








